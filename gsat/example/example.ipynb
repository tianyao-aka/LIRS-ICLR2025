{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1t0_4BxEJ0XncyYvn_VyEQhxwNMvtSUNx?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "WARNING:root:The OGB package is out of date. Your version is 1.3.5, while the latest version is 1.3.6.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from gsat import GSAT, ExtractorMLP\n",
    "from utils import get_data_loaders, get_model, set_seed, Criterion, init_metric_dict, load_checkpoint\n",
    "from trainer import run_one_epoch, update_best_epoch_res, get_viz_idx, visualize_results\n",
    "from datetime import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ogbg_molbace'\n",
    "# dataset_name = 'mutag'\n",
    "model_name = 'GIN'\n",
    "\n",
    "# dataset_name = 'ogbg_molhiv'\n",
    "# model_name = 'PNA'\n",
    "\n",
    "method_name = 'GSAT'\n",
    "cuda_id = -1\n",
    "seed = 0\n",
    "set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n",
    "device = torch.device(f'cuda:{cuda_id}' if cuda_id >= 0 else 'cpu')\n",
    "\n",
    "if model_name == 'GIN':\n",
    "    model_config = {'model_name': 'GIN', 'hidden_size': 64, 'n_layers': 4, 'dropout_p': 0.3, 'use_edge_attr': True}\n",
    "else:\n",
    "    assert model_name == 'PNA'\n",
    "    model_config = {'model_name': 'PNA', 'hidden_size': 80, 'n_layers': 4, 'dropout_p': 0.3, 'use_edge_attr': False, \n",
    "                    'atom_encoder': True, 'aggregators': ['mean', 'min', 'max', 'std'], 'scalers': False}\n",
    "\n",
    "metric_dict = deepcopy(init_metric_dict)\n",
    "model_dir = data_dir / dataset_name / 'logs' / (datetime.now().strftime(\"%m_%d_%Y-%H_%M_%S\") + '-' + dataset_name + '-' + model_name + '-seed' + str(seed) + '-' + method_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using train splits!\n",
      "[INFO] Calculating degree...\n",
      "train/val/test split:\n",
      "896 384 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyao/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/Users/tianyao/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The given 'InMemoryDataset' only references a subset of examples of the full dataset, but 'data' will contain information of the full dataset. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "loaders, test_set, x_dim, edge_attr_dim, num_class, aux_info = get_data_loaders(data_dir, dataset_name, batch_size=batch_size, random_state=seed,\n",
    "                                                                                splits={'train': 0.8, 'valid': 0.1, 'test': 0.1}, \n",
    "                                                                                mutag_x=True if dataset_name == 'mutag' else False)\n",
    "model_config['deg'] = aux_info['deg']\n",
    "print ('train/val/test split:')\n",
    "print (len(loaders['train'])*batch_size,len(loaders['valid'])*batch_size,len(loaders['test'])*batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using multi_label: False\n"
     ]
    }
   ],
   "source": [
    "clf = get_model(x_dim, edge_attr_dim, num_class, aux_info['multi_label'], model_config, device)\n",
    "extractor = ExtractorMLP(model_config['hidden_size'], learn_edge_att=False).to(device)\n",
    "optimizer = torch.optim.Adam(list(extractor.parameters()) + list(clf.parameters()), lr=1e-3, weight_decay=3.0e-6)\n",
    "criterion = Criterion(num_class, aux_info['multi_label'])\n",
    "gsat = GSAT(clf, extractor, criterion, optimizer, learn_edge_att=False, final_r=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Seed 0, Epoch: 0]: gsat_train finished, loss: 2.177, pred: 1.496, info: 0.681, clf_acc: 0.503, clf_roc: 0.474, att_roc: 0.000: 100%|██████████| 7/7 [00:01<00:00,  4.11it/s]\n",
      "[Seed 0, Epoch: 0]: gsat_valid finished, loss: 1.211, pred: 0.763, info: 0.447, clf_acc: 0.631, clf_roc: 0.348, att_roc: 0.000: 100%|██████████| 3/3 [00:00<00:00,  9.63it/s]\n",
      "[Seed 0, Epoch: 0]: gsat_test  finished, loss: 1.211, pred: 0.763, info: 0.447, clf_acc: 0.631, clf_roc: 0.348, att_roc: 0.000: 100%|██████████| 3/3 [00:00<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Seed 0, Epoch: 0]: Best Epoch: 0, Best Val Pred ACC/ROC: 0.000, Best Test Pred ACC/ROC: 0.000, Best Test X AUROC: 0.000\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Seed 0, Epoch: 1]: gsat_train finished, loss: 1.571, pred: 0.934, info: 0.636, clf_acc: 0.484, clf_roc: 0.490, att_roc: 0.000: 100%|██████████| 7/7 [00:01<00:00,  5.41it/s]\n",
      "[Seed 0, Epoch: 1]: gsat_valid finished, loss: 1.078, pred: 0.684, info: 0.394, clf_acc: 0.534, clf_roc: 0.558, att_roc: 0.000: 100%|██████████| 3/3 [00:00<00:00, 14.30it/s]\n",
      "[Seed 0, Epoch: 1]: gsat_test  finished, loss: 1.078, pred: 0.684, info: 0.394, clf_acc: 0.534, clf_roc: 0.558, att_roc: 0.000: 100%|██████████| 3/3 [00:00<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Seed 0, Epoch: 1]: Best Epoch: 0, Best Val Pred ACC/ROC: 0.000, Best Test Pred ACC/ROC: 0.000, Best Test X AUROC: 0.000\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Seed 0, Epoch: 2]: gsat_train finished, loss: 1.356, pred: 0.760, info: 0.596, clf_acc: 0.560, clf_roc: 0.503, att_roc: 0.000: 100%|██████████| 7/7 [00:01<00:00,  5.34it/s]\n",
      "[Seed 0, Epoch: 2]: gsat_valid finished, loss: 0.992, pred: 0.672, info: 0.320, clf_acc: 0.631, clf_roc: 0.484, att_roc: 0.000: 100%|██████████| 3/3 [00:00<00:00, 13.36it/s]\n",
      "[Seed 0, Epoch: 2]: gsat_test  finished, loss: 0.992, pred: 0.672, info: 0.320, clf_acc: 0.631, clf_roc: 0.484, att_roc: 0.000: 100%|██████████| 3/3 [00:00<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Seed 0, Epoch: 2]: Best Epoch: 0, Best Val Pred ACC/ROC: 0.000, Best Test Pred ACC/ROC: 0.000, Best Test X AUROC: 0.000\n",
      "==================================================\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Seed 0, Epoch: 3]: gsat_train........., loss: 1.298, pred: 0.731, info: 0.567, clf_acc: 0.547:  29%|██▊       | 2/7 [00:00<00:01,  2.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vy/4ckz_hjs5z73ghyqnvnwxv980000gn/T/ipykernel_61418/2716158356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_edge_attr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalid_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_edge_attr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_edge_attr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GNN_exp/GSAT-main/example/trainer.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(gsat, data_loader, epoch, phase, dataset_name, seed, use_edge_attr, multi_label)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_edge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mexp_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GNN_exp/GSAT-main/example/trainer.py\u001b[0m in \u001b[0;36mtrain_one_batch\u001b[0;34m(gsat, data, epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mgsat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mgsat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(80):\n",
    "    train_res = run_one_epoch(gsat, loaders['train'], epoch, 'train', dataset_name, seed, model_config['use_edge_attr'], aux_info['multi_label'])\n",
    "    valid_res = run_one_epoch(gsat, loaders['valid'], epoch, 'valid', dataset_name, seed, model_config['use_edge_attr'], aux_info['multi_label'])\n",
    "    test_res = run_one_epoch(gsat, loaders['test'], epoch, 'test', dataset_name, seed, model_config['use_edge_attr'], aux_info['multi_label'])\n",
    "    \n",
    "    metric_dict = update_best_epoch_res(gsat, train_res, valid_res, test_res, metric_dict, dataset_name, epoch, model_dir)\n",
    "    print(f'[Seed {seed}, Epoch: {epoch}]: Best Epoch: {metric_dict[\"metric/best_clf_epoch\"]}, '\n",
    "          f'Best Val Pred ACC/ROC: {metric_dict[\"metric/best_clf_valid\"]:.3f}, Best Test Pred ACC/ROC: {metric_dict[\"metric/best_clf_test\"]:.3f}, '\n",
    "          f'Best Test X AUROC: {metric_dict[\"metric/best_x_roc_test\"]:.3f}')\n",
    "    print('='*50)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = metric_dict['metric/best_clf_epoch']\n",
    "load_checkpoint(gsat, model_dir, model_name=f'gsat_epoch_{best_epoch}', map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pred node label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from utils import process_data, get_preds, save_checkpoint\n",
    "from torch_geometric.explain.metric import groundtruth_metrics,fidelity\n",
    "from torchmetrics import AUROC\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from tqdm import tqdm\n",
    "from trainer import eval_one_batch\n",
    "\n",
    "\n",
    "data_loader_single = DataLoader(loaders['test'].dataset, batch_size=1, shuffle=False)\n",
    "if num_class>=3:\n",
    "    auc_func = AUROC(task='multiclass',num_classes=num_class).to(gsat.device)\n",
    "else:\n",
    "    auc_func = AUROC(task='binary').to(gsat.device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 17/363 [00:00<00:04, 78.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.7012]) tensor([0.5193])\n",
      "tensor([1]) tensor([0.9463]) tensor([0.8453])\n",
      "tensor([0]) tensor([0.4792]) tensor([0.2523])\n",
      "tensor([0]) tensor([0.1554]) tensor([0.2044])\n",
      "tensor([1]) tensor([0.1905]) tensor([0.1584])\n",
      "tensor([0]) tensor([0.2276]) tensor([0.1314])\n",
      "tensor([1]) tensor([0.7034]) tensor([0.3056])\n",
      "tensor([1]) tensor([0.9606]) tensor([0.8395])\n",
      "tensor([0]) tensor([0.1266]) tensor([0.1781])\n",
      "tensor([0]) tensor([0.0520]) tensor([0.0693])\n",
      "tensor([0]) tensor([0.9561]) tensor([0.8598])\n",
      "tensor([1]) tensor([0.7075]) tensor([0.3423])\n",
      "tensor([0]) tensor([0.1693]) tensor([0.2359])\n",
      "tensor([1]) tensor([0.2290]) tensor([0.0899])\n",
      "tensor([1]) tensor([0.8704]) tensor([0.7149])\n",
      "tensor([1]) tensor([0.7045]) tensor([0.5576])\n",
      "tensor([1]) tensor([0.9377]) tensor([0.6949])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 25/363 [00:00<00:05, 60.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.8888]) tensor([0.6602])\n",
      "tensor([0]) tensor([0.5075]) tensor([0.6993])\n",
      "tensor([0]) tensor([0.1807]) tensor([0.5372])\n",
      "tensor([0]) tensor([0.2342]) tensor([0.1381])\n",
      "tensor([0]) tensor([0.0709]) tensor([0.1053])\n",
      "tensor([1]) tensor([0.8102]) tensor([0.6903])\n",
      "tensor([1]) tensor([0.9295]) tensor([0.7868])\n",
      "tensor([0]) tensor([0.0296]) tensor([0.0142])\n",
      "tensor([0]) tensor([0.1679]) tensor([0.5062])\n",
      "tensor([0]) tensor([0.3740]) tensor([0.1054])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 39/363 [00:00<00:05, 60.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.9416]) tensor([0.7278])\n",
      "tensor([0]) tensor([0.3432]) tensor([0.8141])\n",
      "tensor([0]) tensor([0.3901]) tensor([0.2845])\n",
      "tensor([0]) tensor([0.4255]) tensor([0.2118])\n",
      "tensor([1]) tensor([0.9675]) tensor([0.8407])\n",
      "tensor([1]) tensor([0.2181]) tensor([0.1415])\n",
      "tensor([0]) tensor([0.1640]) tensor([0.0893])\n",
      "tensor([1]) tensor([0.6586]) tensor([0.4199])\n",
      "tensor([0]) tensor([0.5953]) tensor([0.5978])\n",
      "tensor([0]) tensor([0.0501]) tensor([0.1137])\n",
      "tensor([1]) tensor([0.9198]) tensor([0.6681])\n",
      "tensor([1]) tensor([0.3146]) tensor([0.1425])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 55/363 [00:00<00:04, 68.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.0639]) tensor([0.0488])\n",
      "tensor([1]) tensor([0.9224]) tensor([0.7968])\n",
      "tensor([0]) tensor([0.1359]) tensor([0.2207])\n",
      "tensor([0]) tensor([0.0982]) tensor([0.2513])\n",
      "tensor([0]) tensor([0.2535]) tensor([0.0989])\n",
      "tensor([0]) tensor([0.1475]) tensor([0.1993])\n",
      "tensor([1]) tensor([0.7881]) tensor([0.6532])\n",
      "tensor([0]) tensor([0.0853]) tensor([0.4381])\n",
      "tensor([0]) tensor([0.1843]) tensor([0.1457])\n",
      "tensor([0]) tensor([0.2267]) tensor([0.2286])\n",
      "tensor([0]) tensor([0.1094]) tensor([0.0733])\n",
      "tensor([1]) tensor([0.4826]) tensor([0.6462])\n",
      "tensor([0]) tensor([0.2181]) tensor([0.0806])\n",
      "tensor([0]) tensor([0.7356]) tensor([0.6804])\n",
      "tensor([0]) tensor([0.3831]) tensor([0.4043])\n",
      "tensor([0]) tensor([0.0228]) tensor([0.0525])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 69/363 [00:01<00:04, 66.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.8240]) tensor([0.5057])\n",
      "tensor([0]) tensor([0.1844]) tensor([0.6918])\n",
      "tensor([0]) tensor([0.1004]) tensor([0.5656])\n",
      "tensor([1]) tensor([0.4873]) tensor([0.4266])\n",
      "tensor([1]) tensor([0.6603]) tensor([0.6408])\n",
      "tensor([0]) tensor([0.1206]) tensor([0.1081])\n",
      "tensor([1]) tensor([0.8228]) tensor([0.6847])\n",
      "tensor([0]) tensor([0.1657]) tensor([0.1482])\n",
      "tensor([0]) tensor([0.2394]) tensor([0.1442])\n",
      "tensor([1]) tensor([0.8550]) tensor([0.5466])\n",
      "tensor([0]) tensor([0.8230]) tensor([0.5192])\n",
      "tensor([1]) tensor([0.1783]) tensor([0.7089])\n",
      "tensor([1]) tensor([0.4789]) tensor([0.0897])\n",
      "tensor([1]) tensor([0.8474]) tensor([0.5646])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 84/363 [00:01<00:04, 69.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.5221]) tensor([0.2082])\n",
      "tensor([0]) tensor([0.0152]) tensor([0.0166])\n",
      "tensor([0]) tensor([0.1922]) tensor([0.2527])\n",
      "tensor([1]) tensor([0.9083]) tensor([0.8504])\n",
      "tensor([0]) tensor([0.0119]) tensor([0.0155])\n",
      "tensor([1]) tensor([0.6171]) tensor([0.2021])\n",
      "tensor([1]) tensor([0.8622]) tensor([0.5865])\n",
      "tensor([0]) tensor([0.2797]) tensor([0.2555])\n",
      "tensor([0]) tensor([0.0378]) tensor([0.1110])\n",
      "tensor([0]) tensor([0.0937]) tensor([0.3189])\n",
      "tensor([0]) tensor([0.1866]) tensor([0.0845])\n",
      "tensor([1]) tensor([0.6201]) tensor([0.4296])\n",
      "tensor([0]) tensor([0.9015]) tensor([0.6488])\n",
      "tensor([1]) tensor([0.9094]) tensor([0.6732])\n",
      "tensor([0]) tensor([0.1630]) tensor([0.1956])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 92/363 [00:01<00:03, 70.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.0832]) tensor([0.1342])\n",
      "tensor([1]) tensor([0.8773]) tensor([0.8045])\n",
      "tensor([1]) tensor([0.9450]) tensor([0.8146])\n",
      "tensor([0]) tensor([0.0879]) tensor([0.2024])\n",
      "tensor([0]) tensor([0.8300]) tensor([0.5941])\n",
      "tensor([1]) tensor([0.8454]) tensor([0.7220])\n",
      "tensor([0]) tensor([0.9414]) tensor([0.7018])\n",
      "tensor([1]) tensor([0.5662]) tensor([0.5362])\n",
      "tensor([0]) tensor([0.2898]) tensor([0.1347])\n",
      "tensor([1]) tensor([0.8372]) tensor([0.4899])\n",
      "tensor([0]) tensor([0.3023]) tensor([0.3133])\n",
      "tensor([0]) tensor([0.0877]) tensor([0.5489])\n",
      "tensor([0]) tensor([0.3876]) tensor([0.4390])\n",
      "tensor([1]) tensor([0.3737]) tensor([0.3698])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 107/363 [00:01<00:03, 64.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.0391]) tensor([0.0334])\n",
      "tensor([0]) tensor([0.0505]) tensor([0.0302])\n",
      "tensor([1]) tensor([0.2584]) tensor([0.3983])\n",
      "tensor([1]) tensor([0.7491]) tensor([0.3512])\n",
      "tensor([0]) tensor([0.1090]) tensor([0.1920])\n",
      "tensor([0]) tensor([0.3133]) tensor([0.1535])\n",
      "tensor([0]) tensor([0.4362]) tensor([0.3424])\n",
      "tensor([0]) tensor([0.1667]) tensor([0.1034])\n",
      "tensor([0]) tensor([0.1387]) tensor([0.1067])\n",
      "tensor([0]) tensor([0.2150]) tensor([0.1277])\n",
      "tensor([0]) tensor([0.2161]) tensor([0.6021])\n",
      "tensor([1]) tensor([0.5140]) tensor([0.3113])\n",
      "tensor([0]) tensor([0.0644]) tensor([0.1409])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 121/363 [00:01<00:04, 57.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.4610]) tensor([0.1406])\n",
      "tensor([1]) tensor([0.7963]) tensor([0.5238])\n",
      "tensor([1]) tensor([0.0842]) tensor([0.0444])\n",
      "tensor([0]) tensor([0.0690]) tensor([0.2478])\n",
      "tensor([0]) tensor([0.1440]) tensor([0.1109])\n",
      "tensor([0]) tensor([0.1158]) tensor([0.4260])\n",
      "tensor([1]) tensor([0.2880]) tensor([0.2452])\n",
      "tensor([1]) tensor([0.8885]) tensor([0.6615])\n",
      "tensor([0]) tensor([0.5720]) tensor([0.2337])\n",
      "tensor([1]) tensor([0.5463]) tensor([0.3572])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 135/363 [00:02<00:03, 60.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.2979]) tensor([0.0732])\n",
      "tensor([0]) tensor([0.5401]) tensor([0.1832])\n",
      "tensor([0]) tensor([0.0939]) tensor([0.1936])\n",
      "tensor([1]) tensor([0.7283]) tensor([0.4798])\n",
      "tensor([0]) tensor([0.3185]) tensor([0.1891])\n",
      "tensor([0]) tensor([0.2580]) tensor([0.0753])\n",
      "tensor([0]) tensor([0.0999]) tensor([0.3145])\n",
      "tensor([1]) tensor([0.0616]) tensor([0.0221])\n",
      "tensor([0]) tensor([0.5397]) tensor([0.3007])\n",
      "tensor([0]) tensor([0.7772]) tensor([0.4165])\n",
      "tensor([0]) tensor([0.2560]) tensor([0.2337])\n",
      "tensor([0]) tensor([0.6000]) tensor([0.3354])\n",
      "tensor([1]) tensor([0.9091]) tensor([0.6345])\n",
      "tensor([1]) tensor([0.7984]) tensor([0.4500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 149/363 [00:02<00:03, 62.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.4313]) tensor([0.2268])\n",
      "tensor([1]) tensor([0.9402]) tensor([0.7264])\n",
      "tensor([0]) tensor([0.1291]) tensor([0.6361])\n",
      "tensor([0]) tensor([0.1981]) tensor([0.5450])\n",
      "tensor([0]) tensor([0.0760]) tensor([0.1857])\n",
      "tensor([1]) tensor([0.8189]) tensor([0.5712])\n",
      "tensor([1]) tensor([0.9353]) tensor([0.7633])\n",
      "tensor([0]) tensor([0.3616]) tensor([0.1365])\n",
      "tensor([1]) tensor([0.9112]) tensor([0.6464])\n",
      "tensor([0]) tensor([0.4050]) tensor([0.2796])\n",
      "tensor([0]) tensor([0.0620]) tensor([0.0975])\n",
      "tensor([1]) tensor([0.2411]) tensor([0.4385])\n",
      "tensor([0]) tensor([0.0174]) tensor([0.0389])\n",
      "tensor([0]) tensor([0.0855]) tensor([0.1140])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 163/363 [00:02<00:03, 64.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.1581]) tensor([0.2187])\n",
      "tensor([1]) tensor([0.8608]) tensor([0.5250])\n",
      "tensor([0]) tensor([0.0527]) tensor([0.0339])\n",
      "tensor([0]) tensor([0.6417]) tensor([0.3388])\n",
      "tensor([0]) tensor([0.0384]) tensor([0.3249])\n",
      "tensor([0]) tensor([0.3845]) tensor([0.3008])\n",
      "tensor([1]) tensor([0.0457]) tensor([0.2915])\n",
      "tensor([0]) tensor([0.1737]) tensor([0.1435])\n",
      "tensor([0]) tensor([0.0499]) tensor([0.0914])\n",
      "tensor([0]) tensor([0.0524]) tensor([0.0811])\n",
      "tensor([0]) tensor([0.5710]) tensor([0.3149])\n",
      "tensor([0]) tensor([0.2149]) tensor([0.0908])\n",
      "tensor([0]) tensor([0.0955]) tensor([0.5588])\n",
      "tensor([1]) tensor([0.3557]) tensor([0.2976])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 178/363 [00:02<00:02, 67.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.7597]) tensor([0.5620])\n",
      "tensor([0]) tensor([0.7031]) tensor([0.2983])\n",
      "tensor([0]) tensor([0.1185]) tensor([0.2015])\n",
      "tensor([0]) tensor([0.9009]) tensor([0.6961])\n",
      "tensor([0]) tensor([0.2771]) tensor([0.2374])\n",
      "tensor([0]) tensor([0.2282]) tensor([0.0574])\n",
      "tensor([0]) tensor([0.2752]) tensor([0.7634])\n",
      "tensor([0]) tensor([0.1327]) tensor([0.2494])\n",
      "tensor([0]) tensor([0.2890]) tensor([0.1250])\n",
      "tensor([1]) tensor([0.9357]) tensor([0.7439])\n",
      "tensor([0]) tensor([0.8021]) tensor([0.4613])\n",
      "tensor([1]) tensor([0.4856]) tensor([0.2498])\n",
      "tensor([0]) tensor([0.0679]) tensor([0.1220])\n",
      "tensor([1]) tensor([0.6809]) tensor([0.5662])\n",
      "tensor([0]) tensor([0.0902]) tensor([0.1171])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 186/363 [00:02<00:02, 69.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.9132]) tensor([0.6107])\n",
      "tensor([0]) tensor([0.3926]) tensor([0.6387])\n",
      "tensor([0]) tensor([0.1279]) tensor([0.0955])\n",
      "tensor([0]) tensor([0.8440]) tensor([0.5523])\n",
      "tensor([0]) tensor([0.1612]) tensor([0.1194])\n",
      "tensor([0]) tensor([0.1067]) tensor([0.3689])\n",
      "tensor([0]) tensor([0.2751]) tensor([0.2165])\n",
      "tensor([0]) tensor([0.2635]) tensor([0.3066])\n",
      "tensor([1]) tensor([0.6594]) tensor([0.2429])\n",
      "tensor([0]) tensor([0.8744]) tensor([0.5160])\n",
      "tensor([0]) tensor([0.1362]) tensor([0.6530])\n",
      "tensor([0]) tensor([0.6677]) tensor([0.4473])\n",
      "tensor([0]) tensor([0.4391]) tensor([0.2294])\n",
      "tensor([1]) tensor([0.9204]) tensor([0.6745])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 200/363 [00:03<00:02, 66.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.9117]) tensor([0.6649])\n",
      "tensor([0]) tensor([0.3298]) tensor([0.4184])\n",
      "tensor([0]) tensor([0.2706]) tensor([0.1440])\n",
      "tensor([0]) tensor([0.1458]) tensor([0.1424])\n",
      "tensor([0]) tensor([0.0175]) tensor([0.0233])\n",
      "tensor([0]) tensor([0.1719]) tensor([0.2091])\n",
      "tensor([0]) tensor([0.0557]) tensor([0.0875])\n",
      "tensor([1]) tensor([0.8058]) tensor([0.6069])\n",
      "tensor([0]) tensor([0.2673]) tensor([0.1276])\n",
      "tensor([0]) tensor([0.4436]) tensor([0.1674])\n",
      "tensor([1]) tensor([0.7841]) tensor([0.5852])\n",
      "tensor([0]) tensor([0.3520]) tensor([0.3824])\n",
      "tensor([0]) tensor([0.1076]) tensor([0.2586])\n",
      "tensor([1]) tensor([0.7747]) tensor([0.6461])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 215/363 [00:03<00:02, 70.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.1179]) tensor([0.6094])\n",
      "tensor([0]) tensor([0.3784]) tensor([0.2701])\n",
      "tensor([0]) tensor([0.0729]) tensor([0.2696])\n",
      "tensor([0]) tensor([0.0785]) tensor([0.0667])\n",
      "tensor([1]) tensor([0.5999]) tensor([0.3909])\n",
      "tensor([0]) tensor([0.0878]) tensor([0.0828])\n",
      "tensor([1]) tensor([0.7137]) tensor([0.5519])\n",
      "tensor([0]) tensor([0.0413]) tensor([0.0706])\n",
      "tensor([1]) tensor([0.8645]) tensor([0.5413])\n",
      "tensor([1]) tensor([0.8201]) tensor([0.7096])\n",
      "tensor([1]) tensor([0.7353]) tensor([0.3298])\n",
      "tensor([1]) tensor([0.4683]) tensor([0.2282])\n",
      "tensor([1]) tensor([0.0545]) tensor([0.0603])\n",
      "tensor([0]) tensor([0.4451]) tensor([0.2494])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 230/363 [00:03<00:02, 58.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.0611]) tensor([0.0598])\n",
      "tensor([0]) tensor([0.3970]) tensor([0.2292])\n",
      "tensor([0]) tensor([0.4141]) tensor([0.2140])\n",
      "tensor([0]) tensor([0.2019]) tensor([0.0883])\n",
      "tensor([0]) tensor([0.3960]) tensor([0.4058])\n",
      "tensor([1]) tensor([0.8353]) tensor([0.7216])\n",
      "tensor([0]) tensor([0.0428]) tensor([0.0605])\n",
      "tensor([1]) tensor([0.5771]) tensor([0.2113])\n",
      "tensor([0]) tensor([0.1024]) tensor([0.2674])\n",
      "tensor([0]) tensor([0.1297]) tensor([0.6415])\n",
      "tensor([0]) tensor([0.2805]) tensor([0.1784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 246/363 [00:03<00:01, 66.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.4951]) tensor([0.3498])\n",
      "tensor([1]) tensor([0.8062]) tensor([0.4654])\n",
      "tensor([1]) tensor([0.9406]) tensor([0.7658])\n",
      "tensor([1]) tensor([0.8466]) tensor([0.7184])\n",
      "tensor([0]) tensor([0.1098]) tensor([0.2157])\n",
      "tensor([1]) tensor([0.5143]) tensor([0.2440])\n",
      "tensor([0]) tensor([0.0638]) tensor([0.1387])\n",
      "tensor([0]) tensor([0.1075]) tensor([0.1406])\n",
      "tensor([0]) tensor([0.1401]) tensor([0.4766])\n",
      "tensor([1]) tensor([0.3453]) tensor([0.0881])\n",
      "tensor([0]) tensor([0.3790]) tensor([0.4333])\n",
      "tensor([1]) tensor([0.2077]) tensor([0.2697])\n",
      "tensor([1]) tensor([0.8774]) tensor([0.7577])\n",
      "tensor([0]) tensor([0.3650]) tensor([0.7466])\n",
      "tensor([1]) tensor([0.6644]) tensor([0.3464])\n",
      "tensor([0]) tensor([0.2167]) tensor([0.1119])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 253/363 [00:03<00:01, 66.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.1841]) tensor([0.2632])\n",
      "tensor([0]) tensor([0.2542]) tensor([0.1017])\n",
      "tensor([0]) tensor([0.3797]) tensor([0.1866])\n",
      "tensor([1]) tensor([0.9380]) tensor([0.7980])\n",
      "tensor([1]) tensor([0.5871]) tensor([0.2120])\n",
      "tensor([1]) tensor([0.8539]) tensor([0.5352])\n",
      "tensor([1]) tensor([0.7789]) tensor([0.3858])\n",
      "tensor([0]) tensor([0.3911]) tensor([0.2345])\n",
      "tensor([0]) tensor([0.2162]) tensor([0.1618])\n",
      "tensor([0]) tensor([0.0126]) tensor([0.0138])\n",
      "tensor([0]) tensor([0.3967]) tensor([0.6793])\n",
      "tensor([1]) tensor([0.3227]) tensor([0.4913])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 267/363 [00:04<00:01, 64.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.1237]) tensor([0.1724])\n",
      "tensor([0]) tensor([0.2286]) tensor([0.6008])\n",
      "tensor([0]) tensor([0.4625]) tensor([0.1285])\n",
      "tensor([0]) tensor([0.3946]) tensor([0.1250])\n",
      "tensor([0]) tensor([0.3889]) tensor([0.1922])\n",
      "tensor([1]) tensor([0.3475]) tensor([0.0936])\n",
      "tensor([0]) tensor([0.3981]) tensor([0.4022])\n",
      "tensor([0]) tensor([0.7901]) tensor([0.6274])\n",
      "tensor([1]) tensor([0.4378]) tensor([0.3720])\n",
      "tensor([1]) tensor([0.2654]) tensor([0.3146])\n",
      "tensor([0]) tensor([0.2734]) tensor([0.1007])\n",
      "tensor([1]) tensor([0.3652]) tensor([0.2996])\n",
      "tensor([0]) tensor([0.3953]) tensor([0.1861])\n",
      "tensor([0]) tensor([0.8874]) tensor([0.5984])\n",
      "tensor([0]) tensor([0.1172]) tensor([0.1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 282/363 [00:04<00:01, 68.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.1862]) tensor([0.1512])\n",
      "tensor([1]) tensor([0.7624]) tensor([0.6259])\n",
      "tensor([0]) tensor([0.1741]) tensor([0.0912])\n",
      "tensor([0]) tensor([0.2928]) tensor([0.0979])\n",
      "tensor([0]) tensor([0.1529]) tensor([0.0565])\n",
      "tensor([0]) tensor([0.4518]) tensor([0.2233])\n",
      "tensor([1]) tensor([0.9045]) tensor([0.6904])\n",
      "tensor([0]) tensor([0.3966]) tensor([0.1234])\n",
      "tensor([0]) tensor([0.3348]) tensor([0.1594])\n",
      "tensor([1]) tensor([0.4037]) tensor([0.2545])\n",
      "tensor([0]) tensor([0.1203]) tensor([0.0744])\n",
      "tensor([1]) tensor([0.6752]) tensor([0.2632])\n",
      "tensor([1]) tensor([0.4394]) tensor([0.1264])\n",
      "tensor([0]) tensor([0.3726]) tensor([0.5582])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 296/363 [00:04<00:00, 68.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.4825]) tensor([0.2356])\n",
      "tensor([1]) tensor([0.5391]) tensor([0.2021])\n",
      "tensor([0]) tensor([0.7494]) tensor([0.6423])\n",
      "tensor([0]) tensor([0.2458]) tensor([0.1619])\n",
      "tensor([1]) tensor([0.0164]) tensor([0.0490])\n",
      "tensor([0]) tensor([0.1073]) tensor([0.1799])\n",
      "tensor([0]) tensor([0.4648]) tensor([0.1187])\n",
      "tensor([0]) tensor([0.1059]) tensor([0.1669])\n",
      "tensor([1]) tensor([0.9248]) tensor([0.7529])\n",
      "tensor([0]) tensor([0.4247]) tensor([0.2132])\n",
      "tensor([0]) tensor([0.0073]) tensor([0.0213])\n",
      "tensor([0]) tensor([0.8726]) tensor([0.5877])\n",
      "tensor([1]) tensor([0.7273]) tensor([0.4004])\n",
      "tensor([1]) tensor([0.6358]) tensor([0.3850])\n",
      "tensor([0]) tensor([0.2687]) tensor([0.3833])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 311/363 [00:04<00:00, 67.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.7356]) tensor([0.3639])\n",
      "tensor([0]) tensor([0.7316]) tensor([0.5611])\n",
      "tensor([1]) tensor([0.2844]) tensor([0.5821])\n",
      "tensor([1]) tensor([0.0749]) tensor([0.0528])\n",
      "tensor([1]) tensor([0.6510]) tensor([0.4975])\n",
      "tensor([0]) tensor([0.0373]) tensor([0.0838])\n",
      "tensor([0]) tensor([0.0414]) tensor([0.1211])\n",
      "tensor([0]) tensor([0.1313]) tensor([0.0730])\n",
      "tensor([0]) tensor([0.4018]) tensor([0.5798])\n",
      "tensor([1]) tensor([0.3622]) tensor([0.2236])\n",
      "tensor([0]) tensor([0.3716]) tensor([0.2293])\n",
      "tensor([0]) tensor([0.0471]) tensor([0.0486])\n",
      "tensor([0]) tensor([0.1990]) tensor([0.3012])\n",
      "tensor([0]) tensor([0.1494]) tensor([0.2861])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 325/363 [00:04<00:00, 66.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.0885]) tensor([0.1752])\n",
      "tensor([0]) tensor([0.0854]) tensor([0.5321])\n",
      "tensor([1]) tensor([0.8147]) tensor([0.4796])\n",
      "tensor([0]) tensor([0.1122]) tensor([0.0896])\n",
      "tensor([1]) tensor([0.1729]) tensor([0.7738])\n",
      "tensor([0]) tensor([0.1650]) tensor([0.4782])\n",
      "tensor([0]) tensor([0.4111]) tensor([0.6065])\n",
      "tensor([1]) tensor([0.5915]) tensor([0.4122])\n",
      "tensor([1]) tensor([0.7504]) tensor([0.3588])\n",
      "tensor([1]) tensor([0.9305]) tensor([0.6973])\n",
      "tensor([0]) tensor([0.4263]) tensor([0.2288])\n",
      "tensor([1]) tensor([0.4290]) tensor([0.2217])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 339/363 [00:05<00:00, 57.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.8615]) tensor([0.7504])\n",
      "tensor([0]) tensor([0.7350]) tensor([0.3403])\n",
      "tensor([0]) tensor([0.7806]) tensor([0.6642])\n",
      "tensor([0]) tensor([0.0600]) tensor([0.0858])\n",
      "tensor([0]) tensor([0.0693]) tensor([0.1231])\n",
      "tensor([1]) tensor([0.8690]) tensor([0.6519])\n",
      "tensor([1]) tensor([0.7759]) tensor([0.6621])\n",
      "tensor([0]) tensor([0.1189]) tensor([0.2144])\n",
      "tensor([1]) tensor([0.8105]) tensor([0.6786])\n",
      "tensor([1]) tensor([0.9559]) tensor([0.8446])\n",
      "tensor([0]) tensor([0.0197]) tensor([0.0269])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 354/363 [00:05<00:00, 63.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([0.6385]) tensor([0.3796])\n",
      "tensor([0]) tensor([0.5040]) tensor([0.7486])\n",
      "tensor([1]) tensor([0.7902]) tensor([0.5857])\n",
      "tensor([1]) tensor([0.5914]) tensor([0.2002])\n",
      "tensor([0]) tensor([0.1803]) tensor([0.7025])\n",
      "tensor([1]) tensor([0.9372]) tensor([0.8492])\n",
      "tensor([0]) tensor([0.3990]) tensor([0.4299])\n",
      "tensor([1]) tensor([0.6153]) tensor([0.4069])\n",
      "tensor([0]) tensor([0.3362]) tensor([0.2008])\n",
      "tensor([0]) tensor([0.1109]) tensor([0.1643])\n",
      "tensor([1]) tensor([0.9299]) tensor([0.7059])\n",
      "tensor([1]) tensor([0.8570]) tensor([0.6518])\n",
      "tensor([0]) tensor([0.0518]) tensor([0.1720])\n",
      "tensor([0]) tensor([0.0265]) tensor([0.0288])\n",
      "tensor([0]) tensor([0.3143]) tensor([0.2468])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:05<00:00, 65.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([0.2733]) tensor([0.2048])\n",
      "tensor([0]) tensor([0.4483]) tensor([0.6708])\n",
      "tensor([1]) tensor([0.9590]) tensor([0.8020])\n",
      "tensor([0]) tensor([0.2229]) tensor([0.3432])\n",
      "tensor([1]) tensor([0.5704]) tensor([0.3645])\n",
      "tensor([0]) tensor([0.3253]) tensor([0.2243])\n",
      "tensor([0]) tensor([0.7943]) tensor([0.6517])\n",
      "tensor([1]) tensor([0.3595]) tensor([0.1622])\n",
      "Groundtruth Metrics\n",
      "tensor(0.8294) tensor(0.7476)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topK=5\n",
    "gt = []\n",
    "y_hat_preds = []\n",
    "y_hat_removal_preds = []\n",
    "for batch in tqdm(data_loader_single):\n",
    "        batch = batch.to(gsat.device)\n",
    "        att, loss_dict, clf_logits = eval_one_batch(gsat,batch,500)\n",
    "        if num_class<=2:\n",
    "            y = batch.y.view(-1,)\n",
    "            y_hat = torch.sigmoid(clf_logits).detach().cpu().view(-1,)\n",
    "            new_edge_index,new_edge_attr = remove_topk_edges(att,batch,topK)\n",
    "            batch.edge_index = new_edge_index\n",
    "            batch.edge_attr = new_edge_attr\n",
    "            att, loss_dict, clf_logits = eval_one_batch(gsat,batch,500)\n",
    "            y_hat_removal = torch.sigmoid(clf_logits).detach().cpu().view(-1,)\n",
    "            print (y,y_hat,y_hat_removal)\n",
    "            gt.append(y)\n",
    "            y_hat_preds.append(y_hat)\n",
    "            y_hat_removal_preds.append(y_hat_removal)\n",
    "        else:\n",
    "            y = batch.y.view(-1,)\n",
    "            y_hat = torch.softmax(clf_logits,dim=-1).detach().cpu().view(1,-1)\n",
    "            new_edge_index,new_edge_attr = remove_topk_edges(att,batch,topK)\n",
    "            batch.edge_index = new_edge_index\n",
    "            batch.edge_attr = new_edge_attr\n",
    "            att, loss_dict, clf_logits = eval_one_batch(gsat,batch,500)\n",
    "            y_hat_removal = torch.softmax(clf_logits,dim=-1).detach().cpu().view(1,-1)\n",
    "            # print (y,y_hat,y_hat_removal)\n",
    "            gt.append(y)\n",
    "            y_hat_preds.append(y_hat)\n",
    "            y_hat_removal_preds.append(y_hat_removal)\n",
    "            \n",
    "\n",
    "gt = torch.cat(gt,dim=0)\n",
    "y_hat_preds = torch.cat(y_hat_preds,dim=0)\n",
    "y_hat_removal_preds = torch.cat(y_hat_removal_preds,dim=0)\n",
    "print('Groundtruth Metrics')\n",
    "auc1 = auc_func(y_hat_preds,gt)\n",
    "auc2 = auc_func(y_hat_removal_preds,gt)\n",
    "print (auc1,auc2)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4800000000000001, tensor(0.7286))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = calc_optimal_thres(gt,y_hat_preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vy/4ckz_hjs5z73ghyqnvnwxv980000gn/T/ipykernel_56133/2172322361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mfidelity_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfidelity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat_removal_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fidelity+: {fidelity_plus}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/vy/4ckz_hjs5z73ghyqnvnwxv980000gn/T/ipykernel_56133/2172322361.py\u001b[0m in \u001b[0;36mfidelity\u001b[0;34m(target, logits, logits_removed_subgraph)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \"\"\"\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Get the predicted labels from logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mpredicted_labels_removed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_removed_subgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "def calc_optimal_thres(target, preds):\n",
    "    score_dict ={}\n",
    "    thres = np.arange(0.1,1,0.02)\n",
    "    for t in thres:\n",
    "        func = BinaryF1Score(threshold=t)\n",
    "        score = func(preds,target)\n",
    "        score_dict[t] = score\n",
    "    best_thres = max(score_dict,key=score_dict.get)\n",
    "    return best_thres,score_dict[best_thres]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def fidelity(target: torch.Tensor, logits: torch.Tensor, logits_removed_subgraph: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Calculates the fidelity scores based on the given target labels, prediction logits, \n",
    "    and prediction logits after the removal of the explanatory subgraph.\n",
    "\n",
    "    Args:\n",
    "        target (torch.Tensor): A tensor of shape (N,) containing the target labels.\n",
    "        logits (torch.Tensor): A tensor of shape (N, C) containing the prediction logits.\n",
    "        logits_removed_subgraph (torch.Tensor): A tensor of shape (N, C) containing the \n",
    "                                                 prediction logits after removal of the subgraph.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: The fidelity- and fidelity+ scores.\n",
    "    \"\"\"\n",
    "    # Get the predicted labels from logits\n",
    "    predicted_labels = torch.argmax(logits, dim=1)\n",
    "    predicted_labels_removed = torch.argmax(logits_removed_subgraph, dim=1)\n",
    "\n",
    "    # Calculate the fidelity+ score\n",
    "    correct_predictions = (predicted_labels == target).float()\n",
    "    correct_predictions_removed = (predicted_labels_removed == target).float()\n",
    "    \n",
    "    fidelity_plus = torch.mean(torch.abs(correct_predictions - correct_predictions_removed)).item()\n",
    "\n",
    "    return fidelity_plus\n",
    "\n",
    "\n",
    "fidelity_plus = fidelity(gt, y_hat_preds, y_hat_removal_preds)\n",
    "print(f\"Fidelity+: {fidelity_plus}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def remove_topk_edges(attn_score, batch, topK):\n",
    "    \"\"\"\n",
    "    Given an attention score tensor, edge indices, and a value topK, this function removes the\n",
    "    top K edges with the highest attention scores and returns the new edge_index.\n",
    "\n",
    "    Args:\n",
    "        attn_score (torch.Tensor): A tensor of shape (E,) containing the attention scores for each edge.\n",
    "        edge_index (torch.Tensor): A tensor of shape (2, E) containing the edge indices.\n",
    "        topK (int): The number of top attention scores to consider for removal.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the new edge indices after the removal.\n",
    "    \"\"\"\n",
    "    # Get the indices of the top K largest values in attn_score\n",
    "    edge_index = batch.edge_index\n",
    "    if 'edge_attr' in batch:\n",
    "        edge_attr = batch.edge_attr\n",
    "    else:\n",
    "        edge_attr = None\n",
    "    topk_indices = torch.topk(attn_score, topK).indices\n",
    "\n",
    "    # Create a mask to keep all edges except the top K\n",
    "    mask = torch.ones(attn_score.size(0), dtype=torch.bool)\n",
    "    mask[topk_indices] = False\n",
    "\n",
    "    # Apply the mask to edge_index to get the new edge_index\n",
    "    new_edge_index = edge_index[:, mask]\n",
    "    if edge_attr is not None:\n",
    "        new_edge_attr = edge_attr[mask]\n",
    "    else:\n",
    "        new_edge_attr = None\n",
    "\n",
    "    return new_edge_index,new_edge_attr\n",
    "\n",
    "\n",
    "\n",
    "def topk_nodes_from_attn(attn_score: torch.Tensor, edge_index: torch.Tensor, topK: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given an attention score tensor, edge indices, and a value topK, this function returns the \n",
    "    top K nodes with the highest attention scores.\n",
    "\n",
    "    Args:\n",
    "        attn_score (torch.Tensor): A tensor of shape (E,) containing the attention scores for each edge.\n",
    "        edge_index (torch.Tensor): A tensor of shape (2, E) containing the edge indices.\n",
    "        topK (int): The number of top attention scores to consider.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the nodes corresponding to the top K attention scores.\n",
    "    \"\"\"\n",
    "    # Get the indices of the top K largest values in attn_score\n",
    "    topk_indices = torch.topk(attn_score, topK).indices\n",
    "\n",
    "    # Get the corresponding edges from edge_index using the top K indices\n",
    "    topk_edges = edge_index[:, topk_indices]\n",
    "\n",
    "    # Get the unique nodes from the top K edges\n",
    "    topk_nodes = torch.unique(topk_edges)\n",
    "\n",
    "    return topk_nodes\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_edges = []\n",
    "gt_edges = []\n",
    "\n",
    "for batch in data_loader_single:\n",
    "    data = process_data(batch,True)\n",
    "    batch_att, _, _ = eval_one_batch(gsat, data.to(gsat.device), epoch=500)\n",
    "    pred_edges.append(batch_att.view(-1,))\n",
    "    gt_edges.append(data.edge_label.view(-1,))\n",
    "pred_edges = torch.cat(pred_edges)\n",
    "gt_edges = torch.cat(gt_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_viz_samples = 10\n",
    "assert aux_info['multi_label'] is False\n",
    "\n",
    "all_viz_set = get_viz_idx(test_set, dataset_name, num_viz_samples)\n",
    "visualize_results(gsat, all_viz_set, test_set, num_viz_samples, dataset_name, model_config['use_edge_attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_viz_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e720c5032519bc7b462f7dd8f9fcb5b822f5f0841038515fb417505bb6503a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('gnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
